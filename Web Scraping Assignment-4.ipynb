{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593a405f",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "\n",
    "A)Rank \n",
    "\n",
    "B) Name \n",
    "\n",
    "C) Artist \n",
    "\n",
    "D) Upload date \n",
    "\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94c16381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\sonus\\anaconda3\\lib\\site-packages (4.13.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: idna in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6b3d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sonus\\anaconda3\\lib\\site-packages (2.28.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sonus\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11ca2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver = webdriver.Chrome()  # You need to have Chrome WebDriver installed.\n",
    "driver.get(url)\n",
    "\n",
    "# Use Selenium to find and extract the required data here\n",
    "# Remember to handle exceptions for elements that may not be present on the page\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e8175e",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv. \n",
    "\n",
    "Url = https://www.bcci.tv/. \n",
    "\n",
    "You need to find following details: \n",
    "\n",
    "A) Series \n",
    "\n",
    "B) Place \n",
    "\n",
    "C) Date \n",
    "\n",
    "D) Time \n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93bf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Code to navigate to the international fixture page\n",
    "# Extract data using Selenium\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5107472",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "\n",
    "Url = http://statisticstimes.com/ \n",
    "\n",
    "You have to find following details:\n",
    "A) Rank \n",
    "\n",
    "B) State \n",
    "\n",
    "C) GSDP(18-19)- at current prices \n",
    "\n",
    "D) GSDP(19-20)- at current prices \n",
    "\n",
    "E) Share(18-19) \n",
    "\n",
    "F) GDP($ billion) \n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b340bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Code to navigate to the economy page\n",
    "# Extract data using Selenium\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6fea3",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. \n",
    "\n",
    "Url = https://github.com/ \n",
    "\n",
    "You have to find the following details: \n",
    "\n",
    "A) Repository title \n",
    "\n",
    "B) Repository description \n",
    "\n",
    "C) Contributors count \n",
    "\n",
    "D) Language used \n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41f0eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"https://github.com/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Code to navigate to the trending repositories page\n",
    "# Extract data using Selenium\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b3e80",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the \n",
    "\n",
    "following details: \n",
    "\n",
    "A) Song name \n",
    "\n",
    "B) Artist name \n",
    "\n",
    "C) Last week rank \n",
    "\n",
    "D) Peak rank \n",
    "\n",
    "E) Weeks on board \n",
    " \n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2eaec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Code to navigate to the charts and hot 100-page\n",
    "# Extract data using Selenium\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe7e3e",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels. \n",
    "\n",
    "A) Book name \n",
    "\n",
    "B) Author name \n",
    "\n",
    "C) Volumes sold \n",
    "\n",
    "D) Publisher \n",
    "\n",
    "E) Genre \n",
    " \n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c87a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Extract data using Selenium\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b69df0",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "\n",
    "to find the following details: \n",
    "\n",
    "A) Name \n",
    "\n",
    "B) Year span \n",
    "\n",
    "C) Genre \n",
    "\n",
    "D) Run time \n",
    "\n",
    "E) Ratings \n",
    "\n",
    "F) Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81cc4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Extract data using Selenium\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09379f32",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories. \n",
    "\n",
    "Url = https://archive.ics.uci.edu/ You \n",
    "\n",
    "have to find the following details: \n",
    "\n",
    "A) Dataset name \n",
    "\n",
    "B) Data type \n",
    "\n",
    "C) Task \n",
    "\n",
    "D) Attribute type \n",
    "\n",
    "E) No of instances \n",
    "\n",
    "F) No of attribute \n",
    "G) Year \n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8077fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Code to navigate to the Show All Dataset page\n",
    "# Extract data using Selenium\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675d2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
